version: "3.3"
services:
  spark-master:
    build: .
    image: cluster-apache-spark:3.0.2
    ports:
      - "9090:8080"
      - "7077:7077"
    volumes:
       - ./scripts:/opt/spark-apps
       - ./data:/opt/spark-data
    environment:
      - SPARK_LOCAL_IP=spark-master
      - SPARK_WORKLOAD=master
  spark-worker-1:
    image: cluster-apache-spark:3.0.2
    ports:
      - "9091:8080"
      - "7000:7000"
    depends_on:
      - spark-master
    env_file:
      - ./.env
    environment:
      - SPARK_LOCAL_IP=spark-worker-1
    volumes:
       - ./scripts:/opt/spark-apps
       - ./data:/opt/spark-data
  spark-worker-2:
    image: cluster-apache-spark:3.0.2
    ports:
      - "9092:8080"
      - "7001:7000"
    depends_on:
      - spark-master
    env_file:
      - ./.env
    environment:
      - SPARK_LOCAL_IP=spark-worker-2
    volumes:
        - ./scripts:/opt/spark-apps
        - ./data:/opt/spark-data
  demo-database:
    image: postgres:13.7-alpine
    ports: 
      - "5432:5432"
    env_file:
      - ./.env
  zeppelin:
    image: apache/zeppelin:0.10.0
    ports:
      - "8080:8080"
      - "4040:4040"
    volumes:
      - ./spark/spark-3.0.2-bin-hadoop2.7:/opt/spark
      - ./notebooks:/zeppelin/notebook
    environment:
      # - "MASTER=spark://spark-master:7077"
      - "SPARK_MASTER=spark://spark-master:7077"
      - "SPARK_HOME=/opt/spark"

